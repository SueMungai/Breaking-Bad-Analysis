{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "The series Breaking Bad is a critically-acclaimed series with 62 episodes. We want to do a sentiment analysis of how the dialogues of different characters in Breaking Bad and see which characters speak the most, which words they use the most, and how their language changes over time.\n",
    "\n",
    "We would require the series transcripts, to access the dialogues held in the show for this analysis. There are a number of sites that give acces to this. \n",
    "In this case, I used [Forever Dreaming](https://transcripts.foreverdreaming.org/viewforum.php?f=165&sid=18a2d0725580199573a521ce00dc350a), unfortunately only seasons 1-3 had the scripts include the character and the dialogue, in that order, so we will use that in the mean time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL of the page containing the links to all the episodes\n",
    "url = 'https://transcripts.foreverdreaming.org/viewforum.php?f=165'\n",
    "\n",
    "# Send a GET request to the URL and parse the HTML content using BeautifulSoup\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the links to the Breaking Bad episodes on the page\n",
    "episode_links = soup.select('.topictitle')\n",
    "\n",
    "#print(episode_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\Desktop\\DATASCI\\PERSONAL\\Breaking Bad\\Breaking-Bad-Analysis\\notebook.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Apply the get_transcript function to all the episode links\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m episode_data \u001b[39m=\u001b[39m [get_transcript(link) \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m episode_links]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Concatenate all the episode DataFrames into a single DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m full_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(episode_data, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\HP\\Desktop\\DATASCI\\PERSONAL\\Breaking Bad\\Breaking-Bad-Analysis\\notebook.ipynb Cell 4\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Apply the get_transcript function to all the episode links\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m episode_data \u001b[39m=\u001b[39m [get_transcript(link) \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m episode_links]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Concatenate all the episode DataFrames into a single DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m full_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(episode_data, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\HP\\Desktop\\DATASCI\\PERSONAL\\Breaking Bad\\Breaking-Bad-Analysis\\notebook.ipynb Cell 4\u001b[0m in \u001b[0;36mget_transcript\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_transcript\u001b[39m(link):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Send a GET request to the episode link and parse the HTML content\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mhttps://transcripts.foreverdreaming.org/viewforum.php?f=165\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mcontent, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/DATASCI/PERSONAL/Breaking%20Bad/Breaking-Bad-Analysis/notebook.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(soup)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\sessions.py:687\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 687\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    689\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\models.py:838\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    837\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 838\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    840\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\requests\\models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    759\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 760\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    761\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m    762\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\urllib3\\response.py:575\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 575\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[0;32m    576\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[0;32m    577\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\urllib3\\response.py:770\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_chunk(amt)\n\u001b[0;32m    771\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(\n\u001b[0;32m    772\u001b[0m     chunk, decode_content\u001b[39m=\u001b[39mdecode_content, flush_decoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    773\u001b[0m )\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\urllib3\\response.py:723\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    721\u001b[0m     returned_chunk \u001b[39m=\u001b[39m value\n\u001b[0;32m    722\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# amt > self.chunk_left\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m     returned_chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49m_safe_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_left)\n\u001b[0;32m    724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39m_safe_read(\u001b[39m2\u001b[39m)  \u001b[39m# Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\http\\client.py:626\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m s \u001b[39m=\u001b[39m []\n\u001b[0;32m    625\u001b[0m \u001b[39mwhile\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 626\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(\u001b[39mmin\u001b[39;49m(amt, MAXAMOUNT))\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[0;32m    628\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(s), amt)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a function to extract the transcript for a given episode link\n",
    "def get_transcript(link):\n",
    "    # Send a GET request to the episode link and parse the HTML content\n",
    "    response = requests.get('https://transcripts.foreverdreaming.org/viewforum.php?f=165' + link['href'][1:])\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    print(soup)\n",
    "    # Extract the season, episode, and title information from the page heading\n",
    "    heading = soup.select_one('h2')\n",
    "    print(heading)\n",
    "\n",
    "    heading_parts = heading.text.split(' ')\n",
    "    if len(heading_parts) >= 4:\n",
    "        season = heading_parts[1]\n",
    "        episode = heading_parts[3][:-1]\n",
    "        title = ' '.join(heading_parts[4:])\n",
    "    else:\n",
    "        season = 'N/A'\n",
    "        episode = 'N/A'\n",
    "        title = 'N/A'\n",
    "        \n",
    "    # Extract the dialogue from the page content\n",
    "    dialogue = soup.select_one('#pagecontent').find_all('p')\n",
    "    dialogue = [p.text for p in dialogue if not p.text.startswith(('(', '[', 'Scene'))]\n",
    "    \n",
    "    # Split the dialogue into actor and text columns\n",
    "    dialogue = [line for line in dialogue if ':' in line]\n",
    "    dialogue = [{'actor': line.split(':')[0], 'text': line.split(':')[-1].strip()} for line in dialogue]\n",
    "    \n",
    "    # Create a DataFrame with the episode information and dialogue\n",
    "    df = pd.DataFrame(dialogue)\n",
    "    df['season'] = season\n",
    "    df['episode'] = episode\n",
    "    df['title'] = title\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the get_transcript function to all the episode links\n",
    "episode_data = [get_transcript(link) for link in episode_links]\n",
    "\n",
    "# Concatenate all the episode DataFrames into a single DataFrame\n",
    "full_df = pd.concat(episode_data, ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "full_df.to_csv('BBdata.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
