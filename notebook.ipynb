{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "The series Breaking Bad is a critically-acclaimed series with 62 episodes. We want to do a sentiment analysis of how the dialogues of different characters in Breaking Bad and see which characters speak the most, which words they use the most, and how their language changes over time.\n",
    "\n",
    "We would require the series transcripts, to access the dialogues held in the show for this analysis. There are a number of sites that give acces to this. \n",
    "In this case, I used [Forever Dreaming](https://transcripts.foreverdreaming.org/viewforum.php?f=165&sid=18a2d0725580199573a521ce00dc350a), unfortunately only seasons 1-3 had the scripts include the character and the dialogue, in that order, so we will use that in the mean time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode links found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL of the page containing the links to all the episodes\n",
    "url = 'https://transcripts.foreverdreaming.org/viewforum.php?f=165'\n",
    "\n",
    "# Send a GET request to the URL and parse the HTML content using BeautifulSoup\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the links to the Breaking Bad episodes on the page\n",
    "episode_links = soup.select('.topictitle[href*=\"breaking-bad/\"]')\n",
    "\n",
    "if len(episode_links) == 0:\n",
    "    print('No episode links found')\n",
    "else:\n",
    "    # Apply the get_transcript function to all the episode links\n",
    "    episode_data = [get_transcript(link) for link in episode_links]\n",
    "    \n",
    "    # Concatenate all the episode DataFrames into a single DataFrame\n",
    "    full_df = pd.concat(episode_data, ignore_index=True)\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    full_df.to_csv('~/DS3_NLP_BreakingBad_Analysis/Data/BB_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the transcript for a given episode link\n",
    "def get_transcript(link):\n",
    "    # Send a GET request to the episode link and parse the HTML content\n",
    "    response = requests.get('https://transcripts.foreverdreaming.org/viewtopic.php?t=10044' + link['href'][1:])\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the season, episode, and title information from the page heading\n",
    "    heading = soup.select_one('h2')\n",
    "    season = heading.text.split(' ')[1]\n",
    "    episode = heading.text.split(' ')[3][:-1]\n",
    "    title = ' '.join(heading.text.split(' ')[4:])\n",
    "    \n",
    "    # Extract the dialogue from the page content\n",
    "    dialogue = soup.select_one('#pagecontent').find_all('p')\n",
    "    dialogue = [p.text for p in dialogue if not p.text.startswith(('(', '[', 'Scene'))]\n",
    "    \n",
    "    # Split the dialogue into actor and text columns\n",
    "    dialogue = [line for line in dialogue if ':' in line]\n",
    "    dialogue = [{'actor': line.split(':')[0], 'text': line.split(':')[-1].strip()} for line in dialogue]\n",
    "    \n",
    "    # Create a DataFrame with the episode information and dialogue\n",
    "    df = pd.DataFrame(dialogue)\n",
    "    df['season'] = season\n",
    "    df['episode'] = episode\n",
    "    df['title'] = title\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the get_transcript function to all the episode links\n",
    "episode_data = [get_transcript(link) for link in episode_links]\n",
    "\n",
    "# Concatenate all the episode DataFrames into a single DataFrame\n",
    "full_df = pd.concat(episode_data, ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "full_df.to_csv('~/DS3_NLP_BreakingBad_Analysis/Data/BB_data.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(full_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
